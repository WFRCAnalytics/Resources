{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae583467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bhereth\n",
      "C:\\Users\\bhereth\\wfrc-data-f89de5afadfb.json\n",
      "[INFO] Running as: bhereth-wfrcbq@wfrc-data.iam.gserviceaccount.com | Project: wfrc-data\n",
      "[INFO] Reading shapefile: M:\\GitHub\\WF-TDM-v9x\\1_Inputs\\1_TAZ\\Districts\\Dist_Small.dbf\n",
      "[INFO] Reprojecting to EPSG:4326…\n",
      "[INFO] Repairing invalid geometries (make_valid + buffer(0))…\n",
      "[INFO] Writing NDJSON temp file…\n",
      "[INFO] Loading into BigQuery table: wfrc-data.personal_vehicle.small_district_geo\n",
      "[SUCCESS] Loaded 131 rows into wfrc-data.personal_vehicle.small_district_geo.\n",
      "[INFO] Example spatial-join query:\n",
      "\n",
      "WITH bbox AS (\n",
      "  SELECT ST_GeogFromText('POLYGON((\n",
      "    -112.3 40.3,\n",
      "    -111.6 40.3,\n",
      "    -111.6 40.95,\n",
      "    -112.3 40.95,\n",
      "    -112.3 40.3\n",
      "  ))') AS g\n",
      ")\n",
      "SELECT COUNT(*) AS n_tracts\n",
      "FROM `wfrc-data.personal_vehicle.small_district_geo` t\n",
      "JOIN bbox b\n",
      "ON ST_INTERSECTS(t.geom, b.g);\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Load a shapefile into BigQuery with a GEOGRAPHY column.\n",
    "- Reprojects to EPSG:4326\n",
    "- Repairs invalid polygons\n",
    "- Loads via NDJSON to avoid CSV quoting issues\n",
    "\"\"\"\n",
    "\n",
    "import os, re, sys, json, tempfile\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "from shapely.validation import make_valid\n",
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import NotFound, Forbidden, BadRequest\n",
    "import google.auth\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG — edit as needed\n",
    "# -----------------------\n",
    "sys.path.insert(0, '../../2-Python/global-functions')\n",
    "import BigQuery  # provided by you\n",
    "\n",
    "SHAPEFILE = r\"M:\\GitHub\\WF-TDM-v9x\\1_Inputs\\1_TAZ\\Districts\\Dist_Small.dbf\"\n",
    "TARGET_TABLE = \"wfrc-data.personal_vehicle.small_district_geo\"\n",
    "WRITE_DISPOSITION = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def bq_safe_name(s: str) -> str:\n",
    "    s = re.sub(r\"[^\\w]+\", \"_\", s.strip())\n",
    "    s = re.sub(r\"__+\", \"_\", s).strip(\"_\")\n",
    "    if not s or not re.match(r\"^[A-Za-z_]\", s):\n",
    "        s = \"_\" + (s or \"col\")\n",
    "    return s.lower()\n",
    "\n",
    "def infer_bq_type(dtype) -> str:\n",
    "    if pd.api.types.is_integer_dtype(dtype): return \"INT64\"\n",
    "    if pd.api.types.is_float_dtype(dtype):   return \"FLOAT64\"\n",
    "    if pd.api.types.is_bool_dtype(dtype):    return \"BOOL\"\n",
    "    if pd.api.types.is_datetime64_any_dtype(dtype): return \"TIMESTAMP\"\n",
    "    return \"STRING\"\n",
    "\n",
    "def ensure_dataset(client: bigquery.Client, full_table_id: str):\n",
    "    proj, dset, _ = full_table_id.split(\".\")\n",
    "    ds_ref = bigquery.Dataset(f\"{proj}.{dset}\")\n",
    "    try:\n",
    "        client.get_dataset(ds_ref)\n",
    "    except NotFound:\n",
    "        client.create_dataset(ds_ref, exists_ok=True)\n",
    "\n",
    "def assert_can_create_table(client: bigquery.Client, full_table_id: str):\n",
    "    proj, dset, tbl = full_table_id.split(\".\")\n",
    "    ds_id = f\"{proj}.{dset}\"\n",
    "    try:\n",
    "        client.get_dataset(ds_id)\n",
    "    except NotFound:\n",
    "        raise RuntimeError(f\"Dataset {ds_id} does not exist.\")\n",
    "    probe = bigquery.Table(f\"{proj}.{dset}.__perm_probe__\", schema=[bigquery.SchemaField(\"p\",\"STRING\")])\n",
    "    try:\n",
    "        client.create_table(probe)\n",
    "        client.delete_table(probe, not_found_ok=True)\n",
    "    except Forbidden:\n",
    "        raise RuntimeError(f\"No table-create rights on {ds_id}. Grant roles/bigquery.dataEditor.\")\n",
    "\n",
    "def print_running_identity_from_client(client):\n",
    "    # Uses the same creds the client is actually using\n",
    "    creds = getattr(client, \"_credentials\", None)\n",
    "    email = getattr(creds, \"service_account_email\", None) or \"user credentials\"\n",
    "    print(f\"[INFO] Running as: {email} | Project: {client.project}\")\n",
    "\n",
    "# create the client first (env var or explicit path—your choice)\n",
    "# Option A: env var is already set to your SA JSON\n",
    "client = BigQuery.getBigQueryClient_WfrcData()\n",
    "\n",
    "# Option B: pass the SA JSON path explicitly\n",
    "# client = BigQuery.getBigQueryClient_WfrcData(r\"D:\\keys\\wfrc-data.json\")\n",
    "\n",
    "# now print identity based on the actual client\n",
    "print_running_identity_from_client(client)\n",
    "\n",
    "# Ensure dataset and permissions\n",
    "ensure_dataset(client, TARGET_TABLE)\n",
    "assert_can_create_table(client, TARGET_TABLE)\n",
    "\n",
    "# Read shapefile\n",
    "print(f\"[INFO] Reading shapefile: {SHAPEFILE}\")\n",
    "gdf = gpd.read_file(SHAPEFILE)\n",
    "if gdf.empty:\n",
    "    raise ValueError(\"The shapefile appears to be empty.\")\n",
    "if gdf.crs is None:\n",
    "    raise ValueError(\"Shapefile has no CRS. Please define the source CRS before loading.\")\n",
    "\n",
    "# Reproject to EPSG:4326\n",
    "if gdf.crs.to_epsg() != 4326:\n",
    "    print(\"[INFO] Reprojecting to EPSG:4326…\")\n",
    "    gdf = gdf.to_crs(4326)\n",
    "\n",
    "# Repair invalid geometries\n",
    "print(\"[INFO] Repairing invalid geometries (make_valid + buffer(0))…\")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(make_valid)\n",
    "gdf[\"geometry\"] = gdf.geometry.buffer(0)\n",
    "\n",
    "# Drop rows with empty/null geometry\n",
    "before = len(gdf)\n",
    "gdf = gdf[~gdf.geometry.is_empty & gdf.geometry.notna()].copy()\n",
    "dropped = before - len(gdf)\n",
    "if dropped:\n",
    "    print(f\"[WARN] Dropped {dropped} rows with empty/null geometry after repair.\")\n",
    "\n",
    "# Prepare attributes\n",
    "attr_df = gdf.drop(columns=[c for c in gdf.columns if c.lower() == \"geometry\"], errors=\"ignore\").copy()\n",
    "attr_df.columns = [bq_safe_name(c) for c in attr_df.columns]\n",
    "attr_df[\"geom\"] = gdf.geometry.apply(lambda geom: json.dumps(mapping(geom), ensure_ascii=False))\n",
    "\n",
    "# Build schema\n",
    "schema = []\n",
    "for col in attr_df.columns:\n",
    "    if col == \"geom\":\n",
    "        schema.append(bigquery.SchemaField(\"geom\", \"GEOGRAPHY\"))\n",
    "    else:\n",
    "        schema.append(bigquery.SchemaField(col, infer_bq_type(attr_df[col].dtype)))\n",
    "\n",
    "# Write NDJSON and load\n",
    "print(\"[INFO] Writing NDJSON temp file…\")\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", delete=False, encoding=\"utf-8\") as tmp:\n",
    "    for rec in attr_df.to_dict(orient=\"records\"):\n",
    "        tmp.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "    tmp_path = tmp.name\n",
    "\n",
    "print(f\"[INFO] Loading into BigQuery table: {TARGET_TABLE}\")\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=schema,\n",
    "    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    "    write_disposition=WRITE_DISPOSITION,\n",
    "    encoding=\"UTF-8\",\n",
    ")\n",
    "\n",
    "try:\n",
    "    with open(tmp_path, \"rb\") as f:\n",
    "        load_job = client.load_table_from_file(f, TARGET_TABLE, job_config=job_config)\n",
    "    load_job.result()\n",
    "except BadRequest as e:\n",
    "    print(\"[ERROR] BigQuery load failed.\")\n",
    "    if hasattr(e, \"errors\") and e.errors:\n",
    "        for err in e.errors:\n",
    "            print(\" -\", err.get(\"message\"))\n",
    "    raise\n",
    "finally:\n",
    "    try: os.remove(tmp_path)\n",
    "    except Exception: pass\n",
    "\n",
    "tbl = client.get_table(TARGET_TABLE)\n",
    "print(f\"[SUCCESS] Loaded {tbl.num_rows} rows into {TARGET_TABLE}.\")\n",
    "\n",
    "print(\"[INFO] Example spatial-join query:\")\n",
    "print(f\"\"\"\n",
    "WITH bbox AS (\n",
    "  SELECT ST_GeogFromText('POLYGON((\n",
    "    -112.3 40.3,\n",
    "    -111.6 40.3,\n",
    "    -111.6 40.95,\n",
    "    -112.3 40.95,\n",
    "    -112.3 40.3\n",
    "  ))') AS g\n",
    ")\n",
    "SELECT COUNT(*) AS n_tracts\n",
    "FROM `{TARGET_TABLE}` t\n",
    "JOIN bbox b\n",
    "ON ST_INTERSECTS(t.geom, b.g);\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "july2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
